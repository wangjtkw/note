# 第一章 操作系统引论

## 1.1 操作系统的目标和作用

### 1.1.1 操作系统的目标：

方便性、有效性、可扩充性、开放性。

### 1.1.2 操作系统的作用：

- 作为用户与计算机硬件系统之间的接口；
- 作为计算机系统资源的管理者；
- 实现对计算机资源的抽象；

## 1.2 操作系统的发展过程

### 1.2.1 未配置操作系统的计算机系统

- 人工操作方式：
  - 独占全机；
  - CPU等待人工操作；严重降低计算机资源的利用率，此即所谓人机矛盾。
- 脱机输入/输出(Off-Line I/O)方式：
  - 减少了CPU的空闲时间；
  - 提高了I/O的速度。

### 1.2.2 单道批处理系统

单道批处理系统是在解决人际矛盾和CPU与I/O设备速度不匹配矛盾的过程中形成的；

批处理系统旨在提高系统资源的利用率和系统吞吐量；

但这种单道批处理系统仍不能充分的利用系统资源。

缺点：

- 内存中仅有一道程序；
- 每逢该程序在运行中发出I/O请求后，CPU便处于等待状态。

### 1.2.3 多道批处理系统

1. 多道程序设计的基本该概念：
   - 用户所提交的作业先存放在外存上，并排成一个队列，称为"后备队列"；
   - 系统可利用其他程序在进行I/O操作的空档期，调度其他程序运行。
2. 多道批处理系统的优缺点：
   - 资源利用率高；
   - 系统吞吐量大；
   - 平均周转时间长；
   - 无交互能力。
3. 多道批处理系统需要解决的问题：
   - 处理机征用问题；
   - 内存分配和保护问题；
   - I/O设备分配问题；
   - 文件的组织和管理问题；
   - 作业管理问题；
   - 用户与系统的接口问题。

### 1.2.4 分时系统

1. 分时系统的引入：

   - 人机交互。对程序进行直接控制，以方便对程序中的错误进行修改；
   - 共享主机。每个人都希望独占计算机，并且感受不到其他用户的存在。

   分时系统允许多个系统同时通过自己的终端，以交互方式使用计算机，共享主机中的资源。

2. 分时系统实现的关键问题：

   - 及时接收。通过配置多路卡，周期性的扫描各个终端；
   - 及时处理。可以采用让作业直接进入内存或者采用轮转运行方式。

3. 分时系统的特征：

   - 多路性；
   - 独占性；
   - 及时性；
   - 交互性。

### 1.2.5 实时系统

1. 实时系统的类型：

   - 工业(武器)控制系统；
   - 信息查询系统；
   - 多媒体系统；
   - 嵌入式系统。

2. 实时任务的类型：

   - 周期性实时任务和非周期性实时任务：

     - 周期性任务是指外部设备周期性的发出激励信号给计算机，要求他按指定周期循环执行。
     - 非周期性任务无明显周期，但必须有一个截止时间，或称为最后期限。分为开始截至时间和完成截止时间。

   - 硬实时任务和软实时任务：

     - 硬实时任务是指系统必须满足任务对截止时间的要求，否则可能造成难以预测的后果。
     - 软实时任务也要求一个截至时间，但偶尔错过任务截至时间，对系统产生的影响也不大。

   - 实时系统与分时系统的比较：

     - 多路性：

       - 信息查询系统和分时系统多路性表现为系统按分时原则为多个终端用户服务。
       - 实时控制系统多路性是指系统周期性的对多路现场信息进行采集。

     - 独立性：

       - 信息查询系统中每个终端用户与系统进行交互时，彼此之间相互独立不干扰。
       - 实时系统，对信息的采集和对对象的控制也互不干扰。

     - 及时性：

       - 信息查询系统对实时性的要求是根据人所能接受的等待时间来确定。
       - 实时控制系统则是以控制对象所要求的截至时间来确定。

     - 交互性：

       - 分时系统能像终端用户提供数据处理、资源共享等服务。

       - 在信息查询系统中，人与系统的交互性仅限于访问系统中某些特定的专用服务程序。

     - 可靠性：

       - 分时系统要求系统可靠。
       - 实时系统要求系统高度可靠。

### 1.2.6 微机操作系统的发展

1. 单用户单任务操作系统：只允许一个用户上机，且只允许用户程序作为一个任务运行。
2. 单用户多任务操作系统：只允许一个用户上机，但允许用户把程序分为若干个任务，使他们并发执行。
3. 多用户多任务操作系统：允许多个用户通过各自的终端，使用同一台机器，共享主机系统中的各种资源，而每一个用户程序又可进一步分为几个任务，使他们并发执行。

## 1.3 操作系统的基本特性*

### 1.3.1 并发(最基本)

1. 并发与并行：
   - 并发性：是指两个或多个事件在**同一时间间隔**内发生。
   - 并行性：是指两个或多个事件在**同一时刻**发送。
2. 引入进程：
   - 所谓进程，是指在系统中能独立运行并作为资源分配的基本单位。
   - 多个进程之间可以并发执行和交换信息。

### 1.3.2 共享

1. 互斥共享方式：
   - 系统中某些资源虽然可以给多个进程(线程)使用，但应规定在一段时间内，只允许一个进程访问该资源。
   - 系统建立一种机制，保证多个进程对这类资源的互斥访问。
2. 同时访问方式：
   - 有些资源，在宏观上，各个进程(线程)是在同时使用的，但在微观上，实际是对该资源进行交替访问。

### 1.3.3 虚拟

1. 时分复用技术：该种方式提高资源利用率的根本原因在于，它利用某设备为一用户服务的空闲时间，又转去为其他用户服务。
   - 虚拟处理机技术：利用多道程序设计技术，为每道程序建立至少一个进程，让多道程序并发执行。
   - 虚拟设备技术：利用虚拟设备技术，将一台物理I/O设备虚拟为多台逻辑上的I/O设备，并允许每个用户占用一台逻辑上的I/O设备。
2. 空分复用技术：是指将一个频带范围比较宽的信道划分成多个频带范围较窄的信道(称为频带)。
3. 时分复用与空分复用比较：
   - 多道程序技术(时分复用技术)是通过利用处理机的空闲时间运行其他程序。提高了处理机的利用率。
   - 空分复用技术是利用存储器的空闲空间分区存放和运行其它的多道程序，以此来提高内存的利用率。

### 1.3.4 异步

## 1.4 操作系统的主要功能(1:12:43)

传统的OS中应具有处理机管理、存储器管理、设备管理和文件管理等基本功能，为用户使用方便，还应该向用户提供方便的用户接口。

# 第二章 进程的描述与控制

## 2.1 前趋图和程序执行

### 2.1.1 前趋图

- 前趋图是指一个有向无循环图，可记为DAG，它用于描述进程之间执行的先后顺序。
- 应当注意，前趋图中不允许有循环。

### 2.1.2 程序顺序执行

程序顺序执行时的特征：

- 顺序性；指处理机严格按照程序所规定的顺序执行，即每一操作必须在下一操作开始之前结束。
- 封闭性；指程序在封闭的环境下运行，即程序运行时独占全机资源，程序的状态只有本程序才能改变它，程序一旦开始，其执行结果不受外界因素影响。
- 可再现性。指只要程序执行时的环境和初始条件相同，当程序重复执行时，都可以获得相同的结果。

### 2.1.3 程序并发执行

只有在不存在前趋关系的程序之间才有可能并发执行，否则无法并发执行。

程序并发执行时的特征：

- 间断性；程序在并发执行时，由于它们共享系统资源，以及为完成同一项任务而相互合作，致使在这些并发执行的程序之间形成了相互制约的关系。
- 失去封闭性；当系统中存在着多个可以并发执行的程序时，系统中的各种资源将为它们所共享，这些资源的状态也由这些程序来改变，致使其中任一程序在运行时，其环境都必然会受到其它程序的影响。
- 不可再现性。程序在并发执行时，由于失去了封闭性，也将导致其又失去可再现性。

## 2.2 进程的描述

### 2.2.1 进程的定义和特征

1. 进程的定义：

   - 为了使参与并发执行的每个程序(含数据)都能独立地运行，在操作系统中必须为之配置一个专门的数据结构，称为进程控制块(PCB)。
   - 由程序段、数据段和PCB三部分便构成了进程实体(又称进程映像)。

   进程比较典型的定义有：

   - 进程是程序的一次执行；
   - 进程是一个程序及其数据在处理机上顺序执行时所发生的活动；
   - 进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。
   
2. 进程的特征：

   - 动态性(最基本)：进程的实质是进程实体的执行过程。
   - 并发性：指多个进程实体同存于内存中，且能在一段时间内同时运行。
   - 独立性：在传统的OS中，独立性是指进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位，凡未建立PCB的程序都不能作为一个独立的单位参与运行。
   - 异步性：指进程按异步方式运行，即按各自独立的、不可预知的速度向前推进。

### 2.2.2 进程的基本状态及转换

1. 进程的基本状态：
   - 就绪(Ready)状态：指进程处于准备好运行的状态。
   - 执行(Running)状态：指进程已获得CPU，其程序正在执行的状态。
   - 阻塞(Block)状态：指正在执行的进程由于发生某事件(如I/O请求、申请缓冲区失败等)**暂时**无法继续执行时的状态。通常系统将处于阻塞状态的进程排成一个队列，称该队列为阻塞队列。
   
2. 三种基本状态的转换：

   ![进程三种基本状态及其转换](https://github.com/wangjtkw/Test/blob/master/img/%E8%BF%9B%E7%A8%8B%E4%B8%89%E7%A7%8D%E5%9F%BA%E6%9C%AC%E7%8A%B6%E6%80%81%E5%8F%8A%E5%85%B6%E8%BD%AC%E6%8D%A2.jpg)

3. 创建状态和终止状态：

   1. 创建状态：
      - 进程是由创建产生；
      - 首先由进程申请一个空白PCB；
      - 并向PCB中填写用于控制和管理进程的信息；
      - 为该进程分配运行时所必须的资源；
      - 把该进程转入就绪状态并插入就绪队列之中。
   2. 终止状态：
      - 等待操作系统进行善后处理；
      - 最后将PCB清零，并将PCB空间返还系统。

   ### 2.2.3 挂起操作系统和进程状态的转换

   当挂起操作作用于某个进程时，该进程将被挂起，意味着此时该进程处于**静止状态**；

   如果进程正在执行，它将暂停执行；

   若原本处于就绪状态，则该进程此时暂不接受调度；

   与挂起操作对应的操作是激活操作。

   1. 挂起操作引入：
      - 终端用户的需要；
      - 父进程请求；
      - 负荷调节的需要；
      - 操作系统的需要。

   ### 2.2.4 进程管理中的数据结构

   1. 操作系统中用于管理控制的数据结构
      - 内存表；
      - 设备表；
      - 文件表；
      - 用于进程管理的进程表。通常进程表又被称为进程控制块PCB。
   2. 进程控制块PCB的作用
      - 作为独立运行基本单位的标志；PCB已成为进程存在于系统中的唯一标志。
      - 能实现间断性的运行方式；
      - 提供进程管理所需要的信息；
      - 提供进程调度所需要的信息；
      - 实现与其它进程的同步与通信。

   同步机制应遵循的规则

   - 空闲让进；
   - 忙则等待；
   - 有限等待；
   - 让权等待。

### 2.4.3 信号量机制

1. 整型信号量

   - 定义一个用于表示资源数量的整型量S；

   - 通过两个标准的原子操作wait(S) 和signal(S) 来访问。

   - 这两个操作也被称为P、V操作。

     ```
     wait(S){
     	while(S <= 0);
     	S--;
     }
     signal(S){
     	S++;
     }
     ```

2. 记录型信号量

   - 整型信号量机制未遵循 “让权等待” 原则，而是使进程处于 “忙等” 状态。

   - 在该机制中，除了需要一个用于代表资源数目的整型变量 value 外，还应增加一个进程链表指针 list，用于链接所有等待中的进程。
   - 在记录型信号量中，S -> value 的初值表示系统中某类资源的数目，因而又称为资源信号量；
   - 当S.value < 0 时，表示该类资源已分配完毕，因此进程应调用block 原语进行自我阻塞，放弃处理机，并插入到信号量链表S -> list 中。

3. AND 型信号量

   由于记录型信号量一次只能申请一个资源，当多个进程需要多个资源时，因申请顺序的不同，可能产生死锁问题，因此引入了AND 型信号量。

   AND 型信号量的基本思想是：将进程在整个运行过程中需要的所有资源，一次性全部地分配给进程，待进程使用完后再一起释放。

4. 信号量集

   在记录型信号量中，当一次需要N个单位的资源的时候，便需要进行N次 wait(S) 操作，这显然是低效的，甚至会增加死锁的概率。

   另外，当所申请的资源数量低于某一下限值时，还必须进行管控，以确保系统的安全。

   在此，引入了信号量集，它可以根据所需资源的多少，进行一次性的分配，并且，所设置的阀值不再是1，而是下限值 t 。

## 2.6 进程通信

由于进程的互斥与同步，需要在进程间交换一定的信息，故也被一些人归为进程间通信，但只能被称为低级进程通信。

因为：

- 效率低；
- 通信对用户不透明。

### 2.6.1 进程通信的类型

1. 共享存储器系统

   相互通信的进程共享某些数据结构或共享存储区，进程之间能够通过这些空间进行通信。

   - 基于共享数据结构的通信方式：
     - 要求诸进程公用某些数据结构，借以实现诸进程间的信息交换；
     - 这种方式仅适用于传递相对少量的数据，通信效率低下，属于低级通信。
   - 基于共享存储区的通信方式：
     - 为了传输大量数据，在内存中划出了一块共享存储区域；
     - 诸进程课通过对该共享区的读或写交换信息，实现通信，数据的形式和位置甚至访问控制都是由进程控制；

2. 管道(pipe)通信系统

   - 所谓 “管道”，是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又名 pipe 文件。
   - 管道通信必须提供三方面的协调能力
     - 互斥：当一个进程在对pipe执行读/写操作时，其它进程必须等待；
     - 同步：
     - 确认对方是否存在：

3. 消息传递系统

   在该机制中，进程不必借助任何共享存储区或数据结构，而是以格式化的消息为单位，将通信的数据封装在消息中，并利用操作系统提供的一组通信命令完成进程间通信。

4. 客户机-服务器系统

   该种方式主要实现方法分为三类：

   - 套接字：
   - 远程过程调用(RPC)：
   - 远程方法调用：

### 2.6.2 消息传递通信的实现方式

## 2.7 线程(Thread)的基本概念

### 2.7.1 线程的引入

线程的引入，是为了减少程序在并发执行时所付出的空间开销，使OS具有更好的并发性。

1. 进程的两个基本属性

   - 进程是一个可拥有资源的独立单位；
   - 进程又是一个可独立调度和分派的基本单位。

2. 程序并发执行所需付出的时空开销

   - 创建进程：系统在创建进程时，必须为它配置一系列的资源，以及建立相应的PCB。
   - 撤销进程：系统撤销进程时，必须先对其所占有的资源执行回收操作，然后再撤销PCB。
   - 进程切换：对进程进行上下文切换时，需要保留当前进程的CPU环境，设置新选中进程的CPU环境，因而需花费不少的处理机时间。

3. 线程——作为调度和分派的基本单位

   为了使程序更好的并发执行，同时又尽量减少系统的开销，引入了线程。

### 2.7.2 线程与进程的比较

1. 调度的基本单位
   - 在传统OS中，进程是作为独立调度和分派的基本单位，因而进程是能独立运行的基本单位。
   - 在引入线程的OS中，已把线程作为调度和分派的基本单位，因而线程是能独立运行的基本单位。
   - 同一进程中，线程的切换不会引起进程的切换，但进程的切换必然引起线程的切换。
2. 并发性
   - 在引入线程的OS中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可并发执行。
3. 拥有资源
   - 进程可以拥有资源，并作为系统中拥有资源的一个基本单位；
   - 线程本身并不拥有系统资源，而是仅有一点必不可少的、能保证独立运行的资源。
   - 线程除了拥有自己的少量资源外，还允许多个线程共享该进程所拥有的资源。
4. 独立性
   - 在同一个进程中的不同线程之间的独立性要比不同进程之间的独立性低得多.
5. 系统开销
   - 在创建或撤销进程时，系统都要为之分配和回收进程控制块、分配或回收其它资源；
   - 在进程切换时，涉及到进程上下文的切换；
   - 而线程的切换代价远低于进程的。
6. 支持多处理机系统
   - 在多处理机系统中，对于传统的进程，即单线程进程，不管有多少处理机，该进程只能运行在一个处理机中；
   - 但多线程进程，就可以将进程中的多个线程分配到多个处理机上，使它们并行执行，这将加速进程的完成。

### 2.7.3 线程的状态和线程控制块

1. 线程运行的三个状态

   - 执行状态：表示线程已获得处理机而正在运行；
   - 就绪状态：指线程已具备了各种执行条件，只需再获得CPU便可立即执行；
   - 阻塞状态：指线程在执行中因某事件受阻而处于暂停状态。

2. 线程控制块TCB

   如同每个进程有一个进程控制块一样，系统也为每个线程配置了一个线程控制块TCB，TCB包含：

   - 线程标识符：
   - 一组寄存器：
   - 线程运行状态：
   - 优先级：
   - 线程专有存储区：
   - 信号屏蔽：
   - 堆栈指针：

3. 多线程OS中的进程属性

   多线程OS中的进程有以下属性：

   - 进程是一个可拥有资源的基本单位；
   - 多个线程可并发执行；
   - 进程已不是可执行实体。

## 2.8 线程的实现

1. 内核支持线程KST

   该种线程实现方式的优点：

   - 在多处理机系统中，内核能够同时调用同一个进程中的多个线程并行执行；
   - 如果进程中的一个线程被阻塞了，内核可以调度该进程中的其它线程占有处理器运行，也可以运行其它线程中的进程；
   - 内核支持线程具有很小的数据结构和堆栈，线程的切换比较快，切换开销小；
   - 内核本身也可以采用多线程技术，可以提高系统的执行速度和效率。

   缺点是：对于用户线程切换来说，其模式切换的开销较大，在进行线程切换时，需要先从用户态转到内核态进行。

2. 用户级线程ULT

   - 用户级线程是在用户空间中实现的；
   - 对线程的创建、撤销、同步与通信等功能，都无需内核的支持，即用户级线程是与内核无关的；
   - 对于设置了用户级线程的系统，其调度仍是以进程为单位进行的，在采用轮转调度算法时，多个用户线程共同占有一个时间片，所以实际上并没有完全的公平，

   用户线程的优点：

   - 线程切换不需要转换到内核空间；
   - 调度算法可以是进程专用的；
   - 用户级线程的实现与OS平台无关，所有的应用程序都可以对之进行共享；

   用户线程的缺点：

   - 系统调用的阻塞问题；
   - 在单纯的用户级线程实现方式中，多线程应用不能利用多处理机进行多重处理的优点，内核每次分配给一个进程的仅有一个CPU，因此，进程中仅有一个线程能执行，在该线程放弃CPU之前，其它线程只能等待。

3. 组合方式

   1. 多对一模型：即将用户线程映射到一个内核控制线程；

      优点：线程管理的开销小，效率高；

      缺点：

      - 一个线程在访问内核时发生阻塞，则整个进程都会被阻塞；
      - 在任一时刻，只有一个线程能够访问内核，多个线程不能同时在多个处理机上运行。

   2. 一对一模型：即将每一个用户级线程映射到一个内核支持线程；

      优点：

      - 当一个线程阻塞时，允许调度另一个进程运行，所以它提供了比多对一更好的并发功能；
      - 在多处理机系统中，它允许多个进程并行的运行在多处理机系统上；

      缺点：每创建一个用户线程，相应地需要创建一个内核线程，开销较大，因此需要限制整个系统的线程数。

   3. 多对多模型：即将许多用户线程映射到同样数量或更少数量的内核线程上；

      优点：

      - 可以像一对一模型那样，使一个进程的多个线程并行地运行在多处理机系统上；
      - 也可以像多对一模型那样，减少线程的管理开销和提高效率。

# 第三章 处理机调度与死锁

## 3.1 处理机调度的层次和调度算法的目标

### 3.1.1 处理机调度的层次

1. 高级调度：
   - 高级调度又称长调度或作业调度，它的调度对象是作业；
   - 主要功能是决定将外存上处于后备队列中的哪几个作业调入内存，为它们创建进程、分配必要资源并放入就绪队列；
   - 高级调度主要用于多道批处理系统中，而在分时和实时系统中不设置高级调度。
2. 低级调度：
   - 低级调度又称为进程调度或短程调度，其调度对象是进程(或内核级线程)；
   - 主要功能是决定就绪队列中的哪个进程应获得处理机，并由分派程序将处理机分配给被选中的进程；
   - 进程调度是**最基本**的一种调度，在多道批处理、分时、实时系统中都必须配置这级调度。
3. 中级调度：
   - 中级调度又称为内存调度，它的主要目的是提高内存利用率和系统吞吐量；
   - 应把那些暂时不能运行的进程，调至外存等待，此时进程的状态称为就绪驻外存状态(或挂起状态)；
   - 当挂起状态进程已具备运行条件且内存又稍有空闲时，由中级调度把外存上那些已具备运行条件的就绪进程再重新调入内存，并修改其状态为就绪状态；

### 3.1.2 处理机调度算法的目标

1. 处理机调度算法的共同目标
   - 资源利用率：为提高系统资源的利用率，应使系统中的处理机和其它所有资源都尽可能的保持忙碌状态；
   - 公平性：公平性是指应使诸进程都获得合理的CPU时间，不会发生进程饥饿现象；
   - 平衡性：由于在进程中可能具有多种类型的进程，为使系统中的CPU和各种外部设备都能经常处于忙碌状态，调度算法应尽可能保持系统资源使用的平衡性；
   - 策略强制执行：
2. 批处理系统的目标
   - 平均周转时间短：
   - 系统吞吐量高：
   - 处理机利用率高：
3. 分时系统的目标
   - 响应时间快：
   - 均衡性：
4. 实时系统的目标：
   - 截止时间的保证：
   - 可预测性：

## 3.2 作业与作业调度

### 3.2.1 批处理系统中的作业

1. 作业和作业步

   - 作业：

     - 作业不仅包含了通常的程序和数据，而且还应配有一份作业说明书；

     - 在批处理系统中，是以作业为基本单位从外存调入内存的。

   - 作业步：

     - 在作业运行期间，每个作业都必须经过若干个相对独立，又相互关联的顺序加工步骤才能得到结果。
2. 作业控制块(JCB)
- 为了管理和调度作业，在多道批处理系统中，为每个作业设置了一个作业控制块PCB；
  - 它是作业在系统中存在的标志；
  - JCB中包含的内容包括：作业标识、用户名称、用户账号、作业类型(CPU繁忙型、I/O繁忙型、批量型、终端型)、作业状态、调度信息(优先级、作业运行时间)、资源需求(预计运行时间、要求内存大小等)、资源使用情况等。
3. 作业运行的三个阶段和三种状态
   - 三个阶段：
     - 收容阶段：后备状态，
     - 运行阶段：运行状态，
     - 完成阶段：完成状态，

### 3.2.2 作业调度的主要任务

主要任务是：

- 根据JCB中的信息，检查系统中的资源能否满足作业对资源的需求；
- 以及按照一定的调度算法，从外存的后备队列中选取某些作业调入内存；
- 并为它们创建进程、分配必要的资源；
- 然后再将新创建的进程排在就绪队列上等待资源。

### 3.2.3 先来先服务(FCFS)和短作业优先(SJF)调度算法

1. 先来先服务(FCFS)调度算法

   - FCFS算法是最简单的调度算法，该算法既可用于作业调度，又可用于进程调度；
   - 当在作业调度中采用该算法时，系统将按照作业到达的先后次序来进行调度；
   - 或者说它是优先考虑在系统中等待时间最长的作业，而不管该作业所需执行的时间。
   - FCFS算法在单处理机系统中已经很少作为主调度算法，但经常把它与其它一些调度算法相结合，形成一种更有效的调度算法。

2. 短作业优先(SJF)调度算法

   - 由于在实际情况中，短作业(进程)占有很大比例，为使它们能比长作业优先执行，产生了此算法；
   - 作业越短，优先级越高；

   短作业优先算法的缺点：

   - 必须预知作业的运行时间；
   - 对长作业非常不利；
   - 在采用SJF算法时，人机无法实现交互；
   - 该调度算法完全未考虑作业的紧迫程度。

### 3.2.4 优先级调度算法和高响应比优先调度算法

1. 优先级调度算法：是基于作业的紧迫程度，由外部赋予作业相应的优先级，调度算法是根据该优先级进行调度的。

2. 高响应比优先调度算法：

   - 该算法既考虑了作业的等待时间，又考虑了作业运行时间的调度算法；

   - 优先级的变化规律：
     $$
     优先权 = \frac{等待时间 + 要求服务时间}{要求服务时间}
     $$

   - 由于等待时间之和就是系统对该作业的响应时间，故该优先级又相当于响应比Rp：
     $$
     R_P = \frac{等待时间 + 要求服务时间}{要求服务时间} = \frac{响应时间}{要求服务时间}
     $$

   由上公式可看出：

   - 如果作业的等待时间相同，则要求服务的时间越短，优先权越高；
   - 当要求服务的时间相同时，作业的优先权又取决于其等待时间；
   - 对于长作业的优先级，可随着其等待时间的增加而提高；
   - 但在每次调度之前，都需要先做响应比的计算，会增加系统开销。

## 3.3 进程调度

### 3.3.1 进程调度的任务、机制和方式

1. 进程调度的任务：

   - 保存处理机的现场信息：
   - 按某种算法选取进程：
   - 把处理机分配给进程：

2. 进程调度机制：

   - 排队器：
   - 分派器：
   - 上下文切换器：在对处理机进行切换时，会发生两对上下文的切换操作：
     - 对上下文切换时，OS将保存当前进程的上下文，即把当前进程的处理机寄存器内容保存到该进程的进程控制块内的相应单元，再装入分派程序的上下文，以便分派程序运行；
     - 移出分派程序的上下文，把新选进程的CPU现场信息装入到处理机的各个相应寄存器中，以便新选进程运行。

3. 进程调度方式：

   - 非抢占方式：一旦处理机分配给某个进程后，就一直让它运行下去，直至该进程运行完毕，或发生某事件而被阻塞时，才把处理机分配给其它进程。

   - 抢占方式：这种调度方式允许调度程序根据某种原则，去暂停某个正在执行的进程，将已分配给该进程的处理机重新分配给另一进程。

     抢占方式遵循的原则有：

     - 优先权原则：
     - 短进程优先原则：
     - 时间片原则；

### 3.3.2 轮转调度算法

1. 轮转法的基本原理：

   在轮转(RR)法中，系统将所有就绪进程按FCFS策略排成一个就绪队列，每次执行队首进程；

2. 进程切换的时机：

   - 若一个时间片尚未用完，正在运行的进程就已经完成，就立即激活调度程序，将它从就绪队列中删除，再调度就绪队列中队首的进程运行，并启动一个新的时间片；
   - 在一个时间片用完时，计时器中断处理程序被激活。
   
3. 时间片大小的确定

   - 若选择很小的时间片，将有利于短作业，但时间片选择得太小，意味着会频繁地执行进程调度和进程上下文切换，这会增加系统开销；
   - 若时间片选择太长，且为使每个进程都能在一个时间片内完成，RR算法便退化为FCFS算法。
   - 一个较为可取的时间片大小是略大于一次典型交互所需要的时间，使大多数交互式进程能在一个时间片内完成，从而可以获得很小的响应时间。

### 3.3.3 优先级调度算法

1. 优先级调度算法的类型
   - 非抢占式优先级调度算法：
   - 抢占式优先级调度算法：
2. 优先级的类型：
   - 静态优先级：
     - 静态优先级是在创建进程时确定的，在整个运行期间保持不变，优先级是利用某一范围内的一个整数来表示的，又把该整数称为优先数；
     - 确定优先级大小的依据有：
       - 进程类型：通常系统进程(如接收进程、对换进程)的优先级高于一般用户进程的优先级；
       - 进程对资源的需求：对资源要求较少的进程应赋予较高的优先级；
       - 用户要求：根据进程的紧迫程度及用户所付费用的多少确定优先级。
   - 动态优先级：
     - 动态优先级是指在进程创建之初，会赋予其一个优先级，然后其值会随着进程的推进或等待时间的增加而改变，以便获得更好的调度性能。

### 3.3.4 多队列调度算法

- 该算法将系统中的进程就绪队列从一个拆分为若干个，
- 将不同类型或性质的进程固定分配在不同的就绪队列，
- 不同的就绪队列采用不同的调度算法，
- 一个就绪队列中的进程可以设置不同的优先级，
- 不同的就绪队列本身也可设置不同的优先级。

### 3.3.5 多级反馈队列调度算法

该算法不必事先知道各种进程所需的执行时间，还可以较好的满足各种类型进程的需要。

1. 调度机制：

   - 设置多个就绪队列：在系统中设置多个就绪队列，并为每个就绪队列赋予不同的优先级，该算法为不同队列中的进程所赋予的执行时间片的大小也各不相同，在优先级越高的队列中，其时间片就越小。
   - 每个就绪队列都采用FCFS算法：
   - 按队列优先级调度：

2. 调度算法的性能：

   如果规定第一个队列的时间片略大于多少人机交互所需的处理时间时，便能较好的满足各种类型用户的需要。

   - 终端型用户：该类用户提交的作业多为交互型作业，通常较小，只要在第一队列规定时间完成就行；
   - 短批处理作业用户：
   - 长批处理作业用户：

## 3.5 死锁概述

### 3.5.1 资源问题

1. 可重用性资源和消耗性资源
   - 可重用性资源：可重用性资源是一种可供用户重复使用多次的资源，它的性质有：
     - 每一个可重用性资源中的单元只能分配给一个进程使用，不允许多个进程共享；
     - 进程在使用可重用性资源时，必须按照：请求资源，使用资源，释放资源的顺序进行；
     - 系统中每一类可重用性资源中的单元数目是 相对固定的，进程在运行期间既不能创建也不能删除它。
   - 可消耗性资源：又称临时性资源，它在进程运行期间，由进程动态的创建和消耗，它的性质有：
     - 每一类可消耗性资源的单元数目在进程运行期间是可以不断变化的；
     - 进程在运行过程中，可以不断地创建可消耗性资源的单元；
     - 进程在运行过程中，可以请求若干个可消耗性资源单元，并且不再将它们返回给该资源类中。
2. 可抢占性资源和不可抢占性资源
   - 可抢占性资源：指某个进程在获得这类资源后，该资源可以再被其它进程或系统抢占；这类资源不会引起死锁；
   - 不可抢占性资源：一旦系统把某资源分配给该进程后，就不能将它强行收回，只能在进程用完后自行释放。

### 3.5.2 计算机系统中的死锁

1. 竞争不可抢占性资源引起死锁
2. 竞争可消耗资源引起死锁
3. 进程推进顺序不当引起死锁

### 3.5.3 死锁的定义、必要条件和处理方法

1. 死锁的定义

   如果一组进程中的每一个进程都在等待仅由该组进程中的其它进程才能引发的事件，那么该组进程是死锁的。

2. 产生死锁的必要条件

   - 互斥条件：进程对所分配到的资源进行排它性使用，即在一段时间内，某资源只能被一个进程占用；
   - 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其它进程所占有，此时请求进程会被阻塞，但对自己已获得的资源保持不放；
   - 不可抢占条件：进程已获得的资源在未使用完之前不能被抢占，只能在进程使用完时由自己释放；
   - 循环等待条件：在发生死锁时，必然存在一个进程——资源循环链。

3. 处理死锁的方法

   - 预防死锁：该方法是通过设置某些限制条件，去破坏产生死锁四个必要条件中的一个或几个来预防产生死锁；
   - 避免死锁：该方法是在资源的动态分配过程中，用某种方法防止系统进入不安全状态，从而可以避免发生死锁；
   - 检测死锁：该方法运行进程在运行过程中发生死锁，但可通过检测机构及时地检测出死锁的发生，然后采取适当的措施，把进程从死锁中解脱出来；
   - 解除死锁：当检测到系统中已经发生死锁时，就采取相应的措施，将进程从死锁状态中解脱出来，常用的方法是撤销一些进程，回收它们的资源，将它们分配给已处于阻塞状态的进程，使其能继续运行。

## 3.6 预防死锁

### 3.6.1 破坏“请求和保持”条件

为了破坏该条件，系统必须保证做到：当一个进程在请求资源时，它不能持有不可抢占资源。有两种协议可实现：

1. 第一种协议：
   - 该协议规定，在进程开始之前，必须一次性申请其在整个运行过程中所需的全部资源；
   - 该种方式的优点是简单、易行且安全；
   - 缺点是：
     - 资源被严重浪费，严重的恶化了资源的利用率；
     - 使进程经常会出现饥饿状态。
2. 第二种协议：
   - 该种方式运行一个进程只获得运行初期所需要的资源后，便可开始运行；
   - 进程运行过程中再逐步释放已分配给自己的、且已用毕的资源，然后再请求新的资源。

### 3.6.2 破坏“不可抢占”条件

- 当一个已经保持了某些不可被抢占资源的进程，提出新的资源请求而不能得到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。
- 该种方式实现起来比较复杂，且需付出很大的代价。

### 3.6.3 破坏“循环等待”条件

- 一个能保证“循环等待”条件不成立的办法是：对系统所有资源类型进行线性排序，并赋予不同的序号；
- 在进行排序后，规定每个进程必须按序号递增的顺序请求资源。

## 3.7 避免死锁

### 3.7.1 系统安全状态

- 在死锁避免方法中，把系统的状态分为安全状态和不安全状态；
- 当系统处于安全状态时，可避免发生死锁；
- 反之，当系统处于不安全状态时，则可能进入到死锁状态。

1. 安全状态

   在该方法中，允许进程动态地申请资源，但系统在进行资源分配之前，应计算此次资源分配的安全性；

## 3.7.2 利用银行家

为实现银行家算法：

- 每一个新进程进入系统时，它必须申明在运行过程中，可能需要每种资源类型的最大数目，其数目不应超过系统所拥有的资源总量；
- 当进程请求一组资源时，系统必须首先确定是否有足够的资源分配给该进程；
- 若有，再进一步计算在将这些资源分配给进程后，是否会使系统处于不安全状态；
- 如果不会，才将资源分配给它，否则让进程等待。

## 第四章 存储器管理

## 4.1 存储器的层次结构

### 4.1.1 多层结构的存储器系统

1. 存储器的多层结构
   - 对于通用计算机而言，存储层次至少应具有三级：最高级为CPU寄存器、中间为主存、最底层是辅存。
2. 可执行存储器
   - 在计算机系统的存储层次中，寄存器和主存储器又被称为可执行存储器；
   - 与存放于辅存中的信比较而言，进程可在很少的时钟周期内对可执行存储器进行访问，但对辅存的访问则需要通过I/O设备实现。

### 4.1.2 主存储器与寄存器

1. 主存储器

   简称内存或主存，用于保存进程运行时的程序和数据，也称可执行存储器。

2. 寄存器

   寄存器具有与处理机相同的速度，故对寄存器的访问最快，完全能与CPU协调工作。

### 4.1.3 高速缓存和磁盘缓存

1. 高速缓存

   它是介于寄存器和主存储器之间的存储器，主要用于备份主存中较常用的数据，以减少处理机对主存储器的访问次数。这主要是依靠局部性原理。

2. 磁盘缓存

   由于目前磁盘的I/O速度远低于对主存的访问速度，为了缓和两者之间在速度上的不匹配，而设置了磁盘缓存，主要用于暂时存放频繁使用的一部分磁盘数据和信息，以减少访问磁盘的次数。

## 4.2 程序的装入和链接

用户程序要在系统中运行，必须先将它装入内存，然后再将其转变为一个可执行的程序，通常需要经历以下几个步骤：

- 编译：由编译程序对用户源程序进行编译，形成若干个目标模块；
- 链接：由链接程序将编译后形成的一组目标模块以及它们所需要的库函数链接在一起，形成一个完整的装入模块；
- 装入：由装入程序将装入模块装入内存。

### 4.2.1 程序的装入

1. 绝对装入方式
   - 当计算机系统很小，且仅能运行单道程序时，完全有可能知道程序将驻留在内存的什么位置，绝对装入方式由此而来；
   - 用户程序经编译后，将产生绝对地址(即物理地址)的目标代码；
   - 由于程序中的相对地址(即逻辑地址)与实际内存地址完全相同，故不需要对程序和数据的地址进行修改；
2. 可重定位装入方式
   - 对于用户程序编译所形成的若干个目标模块，它们的起始地址通常都是从0开始的，程序中的其它地址也都是相对于起始地址计算的，所以就为该种方式的实现提供了基础；
   - 通常，把在装入时对目标程序中指令和数据的修改过程称为重定位；
   - 又因为地址变换通道是在进程装入时一次完成的，以后不再改变，故称为静态重定位。
3. 动态运行时装入方式
   - 程序在内存中的移动，意味着它的物理位置发生了变化，这时必须对程序和数据的地址(绝对地址)进行修改后方能运行；
   - 动态运行时的装入程序在把装入模块装入内存后，并不立即把装入模块中的逻辑地址转为物理地址，而是把这种地址转换推迟到程序真正要执行的时候；
   - 因此，装入内存后的所有地址都依旧是逻辑地址；
   - 为使地址转换不影响指令的执行速度，这种方式需要一个重定位寄存器的支持。

### 4.2.2 程序的链接

链接程序的功能是将这组目标模块以及它们所需要的库函数装配成一个完整的装入模块。

1. 静态链接方式

   在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的装配模块，以后不再拆开。

   将目标模块装配为一个装入模块时，需解决两个问题：

   - 对相对地址进行修改：在由编译程序所产生的所有目标模块中，使用的都是相对地址，其起始地址都为0，每个模块中的地址都是相对于起始地址计算的。
   - 变换外部调用符号：
     - 将每个模块中所用的外部调用符号也都变换为相对地址。
     - 这种先进行链接所形成的一个完整的装入模块，又称为可执行文件。
     - 通常都不再把它拆开，要运行时可直接将它装入内存。

2. 装入时动态链接

   这是指将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的链接方式。

   装入时动态链接方式有以下优点：

   - 便于修改和更新： 
   - 便于实现对目标模块的共享：

3. 运行时动态链接

   这种链接方式是将对某些模块的链接推迟到程序执行时才进行。

## 4.3 连接分配存储管理方式

### 4.3.1 单一联系分配

- 在单道程序环境下，内存被分为系统区和用户区，系统区供给OS使用，通常放在内存低址部分；
- 用户区内存，仅装有一道用户程序，整个内存的用户空间由该程序独占。

e















 























